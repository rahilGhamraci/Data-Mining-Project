{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"min_max_normalized_data.csv\"\n",
    "df = pd.read_csv(data_path)\n",
    "classes = df['Target'].unique()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decesion Tree From scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(df,target):\n",
    "\n",
    "    total = len(df) \n",
    "    \n",
    "    # claculating the probabilities pi \n",
    "    probabilities = df[target].value_counts(normalize=True)  # this equivalent to count / total\n",
    "\n",
    "    # Calculate entropy\n",
    "    entropy = -sum(pi * math.log2(pi) for pi in probabilities if pi > 0)\n",
    "\n",
    "    return entropy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gain(df,total_entropy,attribute,target):\n",
    "    \n",
    "    total = len(df)\n",
    "\n",
    "    # Group by attribute values\n",
    "    grouped = df.groupby(attribute)\n",
    "\n",
    "    weighted_entropy = sum(\n",
    "        (len(group) / total) * entropy(group, target)\n",
    "        for _, group in grouped\n",
    "    )\n",
    "    # Calculate information gain\n",
    "    info_gain = total_entropy - weighted_entropy\n",
    "\n",
    "    return info_gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total entropy: 0.9402859586706311\n",
      "Information Gain for Outlook: 0.24674981977443933\n"
     ]
    }
   ],
   "source": [
    "data = {\n",
    "    'Outlook': ['Sunny', 'Sunny', 'Overcast', 'Rain', 'Rain', 'Rain', 'Overcast','Sunny', 'Sunny','Rain','Sunny','Overcast','Overcast','Rain'],\n",
    "    'Temperature': ['Hot', 'Hot', 'Hot', 'Mild', 'Cool', 'Cool', 'Cool', 'Mild', 'Cool', 'Mild', 'Mild', 'Mild', 'Hot', 'Mild'],\n",
    "    'Humidity': ['High', 'High', 'High', 'High', 'Normal', 'Normal', 'Normal', 'High','Normal', 'Normal', 'Normal','High',  'Normal', 'High'],\n",
    "    'Wind': ['Light', 'Strong', 'Light', 'Light', 'Light', 'Strong', 'Strong', 'Light', 'Light', 'Light', 'Strong', 'Strong','Light', 'Strong'],\n",
    "    'PlayTennis': ['No', 'No', 'Yes', 'Yes', 'Yes', 'No', 'Yes','No', 'Yes','Yes', 'Yes', 'Yes','Yes', 'No']\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "attributes = ['Outlook', 'Temperature', 'Humidity', 'Wind']\n",
    "target = 'PlayTennis'\n",
    "\n",
    "# Calculate entropy of the target column\n",
    "total_entropy = entropy(df, 'PlayTennis')\n",
    "print(\"Total entropy:\", total_entropy)\n",
    "\n",
    "# Calculate gain for the attribute 'Outlook'\n",
    "info_gain = gain(df, total_entropy, 'Outlook', 'PlayTennis')\n",
    "print(\"Information Gain for Outlook:\", info_gain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_attribute(df,total_entropy,attributes,target):\n",
    "\n",
    "    info_gains = [(attribute,gain(df, total_entropy, attribute, target)) for attribute in attributes]\n",
    "\n",
    "    # Select the attribute with the maximum information gain\n",
    "    best_attribute = max(info_gains, key=lambda x: x[1])[0]  # Extract the attribute name\n",
    "\n",
    "    return best_attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best attribute: Outlook\n"
     ]
    }
   ],
   "source": [
    "best_attribute = select_attribute(df, total_entropy, attributes, 'PlayTennis')\n",
    "print(\"Best attribute:\", best_attribute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        self.children = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_child(parentNode, node):\n",
    "    parentNode.children.append(node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_tree_algorithm(df, attributes, target, root=None, parentNode=None):\n",
    "    \n",
    "    # Stopping condition: if no attributes left or all target values are the same\n",
    "    if not attributes or len(df[target].unique()) == 1:\n",
    "        # Create a leaf node\n",
    "        leaf_value = df[target].mode()[0]  # Most common target value\n",
    "        leaf_node = Node(leaf_value)\n",
    "        if parentNode:  # Attach leaf to the parent\n",
    "            add_child(parentNode, leaf_node)\n",
    "        return root or leaf_node\n",
    "\n",
    "    # Calculate total entropy\n",
    "    total_entropy = entropy(df, target)\n",
    "\n",
    "    # Select the best attribute to split on\n",
    "    best_attribute = select_attribute(df, total_entropy, attributes, target)\n",
    "\n",
    "    # Create the root node if it doesn't exist\n",
    "    if root is None:\n",
    "        root = Node(best_attribute)\n",
    "        parentNode = root\n",
    "\n",
    "    # Partition the DataFrame by the best attribute\n",
    "    partitions = df.groupby(best_attribute)\n",
    "\n",
    "    # Recurse on each partition\n",
    "    for value, partition in partitions:\n",
    "        # Create a child node for the attribute value\n",
    "        node = Node(f\"{best_attribute}={value}\")\n",
    "        add_child(parentNode, node)\n",
    "\n",
    "        # Filter out the used attribute\n",
    "        remaining_attributes = [attr for attr in attributes if attr != best_attribute]\n",
    "\n",
    "        # Recursively build the tree\n",
    "        decision_tree_algorithm(partition, remaining_attributes, target, root, node)\n",
    "\n",
    "    return root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_tree(node, depth=0):\n",
    "    print(\"  \" * depth + str(node.data))\n",
    "    for child in node.children:\n",
    "        print_tree(child, depth + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outlook\n",
      "  Outlook=Overcast\n",
      "    Yes\n",
      "  Outlook=Rain\n",
      "    Wind=Light\n",
      "      Yes\n",
      "    Wind=Strong\n",
      "      No\n",
      "  Outlook=Sunny\n",
      "    Humidity=High\n",
      "      No\n",
      "    Humidity=Normal\n",
      "      Yes\n"
     ]
    }
   ],
   "source": [
    "root = decision_tree_algorithm(df, attributes, target)\n",
    "print_tree(root)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
